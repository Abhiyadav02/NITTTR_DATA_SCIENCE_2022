{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd11322",
   "metadata": {},
   "source": [
    "1. Importing the libraries\n",
    "2. Importing the Dataset\n",
    "3. Handling of Missing Data\n",
    "4. Handling of Categorical Data\n",
    "5. Splitting the Dataset in Testing and Traning\n",
    "6. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ef18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "# used for handling numbers\n",
    "import pandas as pd\n",
    "# used for handling the dataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "# used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a04a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import the dataset into variable\n",
    "dataset = pd.read_csv('Book2.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df885ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['India ' 49.0 86400.0]\n",
      " ['Brazil' 32.0 57600.0]\n",
      " ['USA' 35.0 64800.0]\n",
      " ['Brazil' 43.0 73200.0]\n",
      " ['USA' 45.0 nan]\n",
      " ['India ' 40.0 69600.0]\n",
      " ['Brazil' nan 62400.0]\n",
      " ['India ' 53.0 94800.0]\n",
      " ['Brazil' nan nan]\n",
      " ['USA ' 55.0 99600.0]\n",
      " ['India ' 42.0 80204.0]]\n",
      "0      NO\n",
      "1     YES\n",
      "2      NO\n",
      "3      NO\n",
      "4     YES\n",
      "5     YES\n",
      "6      NO\n",
      "7     YES\n",
      "8      NO\n",
      "9     YES\n",
      "10    NaN\n",
      "Name: Online_shopper, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# splitting the attributes into independent and dependent\n",
    "# X = features\n",
    "X = dataset.iloc[:,:-1].values # independent variables/ class\n",
    "print(X)\n",
    "# attribute to determine dependent variable/class\n",
    "# Y = labels\n",
    "Y = dataset.iloc[:,-1] # dependent variables/class\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28cb623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.0, 86400.0],\n",
       "       [32.0, 57600.0],\n",
       "       [35.0, 64800.0],\n",
       "       [43.0, 73200.0],\n",
       "       [45.0, 76511.55555555556],\n",
       "       [40.0, 69600.0],\n",
       "       [43.77777777777778, 62400.0],\n",
       "       [53.0, 94800.0],\n",
       "       [43.77777777777778, 76511.55555555556],\n",
       "       [55.0, 99600.0],\n",
       "       [42.0, 80204.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Imputer\n",
    "# Ctrl + I <- help\n",
    "# Handling the missing data and replace missing values\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer = imputer.fit(X[:,1:])\n",
    "imputer\n",
    "X[:,1:] = imputer.transform(X[:,1:])\n",
    "X[:,1:]\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "imputer = imputer.fit(X[:,1:])\n",
    "imputer\n",
    "X[:,1:] = imputer.transform(X[:,1:])\n",
    "X[:,1:]\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imputer = imputer.fit(X[:,1:])\n",
    "imputer\n",
    "X[:,1:] = imputer.transform(X[:,1:])\n",
    "X[:,1:]\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'constant', fill_value = 3)\n",
    "imputer = imputer.fit(X[:,1:])\n",
    "imputer\n",
    "X[:,1:] = imputer.transform(X[:,1:])\n",
    "X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d378a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15976\\2827974881.py:7: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.array(columnTransformer.fit_transform(X), dtype = np.str)\n"
     ]
    }
   ],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])\n",
    "columnTransformer = ColumnTransformer([(\"Region\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X = np.array(columnTransformer.fit_transform(X), dtype = np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7df10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '1.0' '0.0' '0.0' '42.0' '80204.0']\n",
      " ['1.0' '0.0' '0.0' '0.0' '43.77777777777778' '62400.0']\n",
      " ['1.0' '0.0' '0.0' '0.0' '32.0' '57600.0']\n",
      " ['0.0' '1.0' '0.0' '0.0' '53.0' '94800.0']\n",
      " ['1.0' '0.0' '0.0' '0.0' '43.77777777777778' '76511.55555555556']\n",
      " ['1.0' '0.0' '0.0' '0.0' '43.0' '73200.0']\n",
      " ['0.0' '1.0' '0.0' '0.0' '49.0' '86400.0']\n",
      " ['0.0' '1.0' '0.0' '0.0' '40.0' '69600.0']] \n",
      "\n",
      "[['0.0' '0.0' '1.0' '0.0' '45.0' '76511.55555555556']\n",
      " ['0.0' '0.0' '0.0' '1.0' '55.0' '99600.0']\n",
      " ['0.0' '0.0' '1.0' '0.0' '35.0' '64800.0']] \n",
      "\n",
      "10    NaN\n",
      "6      NO\n",
      "1     YES\n",
      "7     YES\n",
      "8      NO\n",
      "3      NO\n",
      "0      NO\n",
      "5     YES\n",
      "Name: Online_shopper, dtype: object \n",
      "\n",
      "4    YES\n",
      "9    YES\n",
      "2     NO\n",
      "Name: Online_shopper, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into traning set and test set\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
    "print(X_train,'\\n')\n",
    "print(X_test,'\\n')\n",
    "print(Y_train,'\\n')\n",
    "print(Y_test,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e75c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler  # used for feature scaling\n",
    "# Sta1ndard Scale\n",
    "sc_X  =StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1aec6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write in csv\n",
    "city = pd.DataFrame([[X_train]], columns = ['Data'])\n",
    "city.to_csv('city_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a742568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
